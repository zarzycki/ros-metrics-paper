%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% AGUJournalTemplate.tex: this template file is for articles formatted with LaTeX
%
% This file includes commands and instructions
% given in the order necessary to produce a final output that will
% satisfy AGU requirements, including customized APA reference formatting.
%
% You may copy this file and give it your
% article name, and enter your text.
%
%
% Step 1: Set the \documentclass
%
%



%% EGU 2-column papers and preprints
\documentclass[nhess, manuscript]{copernicus}
%% AGU
%\documentclass[draft]{agujournal2019}
%\draftfalse
%\journalname{Geophysical Research Letters}

%\usepackage[german, english]{babel}
\usepackage{tabularx}
%\usepackage{cancel}
%\usepackage{multirow}
%\usepackage{supertabular}
%\usepackage{algorithmic}
%\usepackage{algorithm}
%\usepackage{amsthm}
\usepackage{float}
\usepackage{subfig}
\usepackage{rotating}



%\usepackage{url} %this package should fix any errors with URLs in refs.
%\usepackage{lineno}
%\usepackage[inline]{trackchanges} %for better track changes. finalnew option will compile document with changes incorporated.
%\usepackage{soul}
%\linenumbers

%CMZ
%\usepackage{natbib}
%\usepackage{xcolor}
%\usepackage{graphicx}
%\newcommand{\degree}{$^{\circ}$}
%\newcommand{\texttilde}{$\sim$}
%\usepackage{tabularx}
%\renewcommand\tabularxcolumn[1]{m{#1}}% for vertical centering text in X column

%%%%%%%
% As of 2018 we recommend use of the TrackChanges package to mark revisions.
% The trackchanges package adds five new LaTeX commands:
%
%  \note[editor]{The note}
%  \annote[editor]{Text to annotate}{The note}
%  \add[editor]{Text to add}
%  \remove[editor]{Text to remove}
%  \change[editor]{Text to remove}{Text to add}
%
% complete documentation is here: http://trackchanges.sourceforge.net/
%%%%%%%







\begin{document}

%% ------------------------------------------------------------------------ %%
%  Title
%
% (A title should be specific, informative, and brief. Use
% abbreviations only if they are defined in the abstract. Titles that
% start with general keywords then specific terms are optimized in
% searches)
%
%% ------------------------------------------------------------------------ %%



%\title{Differences in algorithmic detection of basin-scale rain-on-snow flood events across gridded data products}

%% ------------------------------------------------------------------------ %%
%
%  AUTHORS AND AFFILIATIONS!
%
%% ------------------------------------------------------------------------ %%

% Authors are individuals who have significantly contributed to the
% research and preparation of the article. Group authors are allowed, if
% each author in the group is separately identified in an appendix.)

% List authors by first name or initial followed by last name and
% separated by commas. Use \affil{} to number affiliations, and
% \thanks{} for author notes.
% Additional author notes should be indicated with \thanks{} (for
% example, for current addresses).

% Example: \authors{A. B. Author\affil{1}\thanks{Current address, Antartica}, B. C. Author\affil{2,3}, and D. E.
% Author\affil{3,4}\thanks{Also funded by Monsanto.}}

%\authors{Colin M. Zarzycki\affil{1}, Benjamin D. Ascher\affil{1}\thanks{now at Colorado State University}, Alan M. Rhoades\affil{2}, and Rachel R. McCrary\affil{3}}

%\affiliation{1}{Department of Meteorology and Atmospheric Science, The Pennsylvania State University, University Park, PA, USA}
%\affiliation{2}{Climate and Ecosystem Sciences Division, Lawrence Berkeley National Laboratory, Berkeley, CA, USA}
%\affiliation{3}{National Center for Atmospheric Research, Boulder, CO, USA}
% \affiliation{4}{Fourth Affiliation}

%% Corresponding Author:
% Corresponding author mailing address and e-mail address:

% (include name and email addresses of the corresponding author.  More
% than one corresponding author is allowed in this LaTeX file and for
% publication; but only one corresponding author is allowed in our
% editorial system.)

% Example: \correspondingauthor{First and Last Name}{email@address.edu}

%\correspondingauthor{Colin M. Zarzycki}{cmz5202@psu.edu}

\Author[1]{Colin M.}{Zarzycki}
\Author[1]{Benjamin D.}{Ascher}
\Author[2]{Alan M.}{Rhoades}
\Author[3]{Rachel R.}{McCrary}

\affil[1]{Department of Meteorology and Atmospheric Science, The Pennsylvania State University, University Park, PA, USA}
\affil[2]{Climate and Ecosystem Sciences Division, Lawrence Berkeley National Laboratory, Berkeley, CA, USA}
\affil[3]{National Center for Atmospheric Research, Boulder, CO, USA}

\correspondence{Colin M. Zarzycki (cmz5202@psu.edu)}

\title{Algorithmically Detected Rain-on-Snow Flood Events in Different Climate Datasets: A Case Study of the Susquehanna River Basin}

%Using the Susquehanna River Basin as an example in how algorithmically detected rain-on-snow flood events differ in climate data
%Algorithmically Detected Rain-on-Snow Flood Events in Different Climate Datasets: A Case Study of the Susquehanna River Basin
%Exploring the Variability of Algorithmically Detected Rain-on-Snow Flood Events in Different Climate Datasets: A Case Study of the Susquehanna River Basin

\runningtitle{Algorithmic detection of basin-scale rain-on-snow events}

\runningauthor{Zarzycki}

\received{}
\pubdiscuss{} %% only important for two-stage journals
\revised{}
\accepted{}
\published{}

%% These dates will be inserted by Copernicus Publications during the typesetting process.


\firstpage{1}

\maketitle




%  List up to three key points (at least one is required)
%  Key Points summarize the main points and conclusions of the article
%  Each must be 100 characters or less with no special characters or punctuation and must be complete sentences

% Example:
% \begin{keypoints}
% \item	List up to three key points (at least one is required)
% \item	Key Points summarize the main points and conclusions of the article
% \item	Each must be 100 characters or less with no special characters or punctuation and must be complete sentences
% \end{keypoints}

% \begin{keypoints}
% \item Rain-on-snow event detection algorithms can objectively isolate historical extremes in gridded climate data products at the basin-scale.
% \item Large discrepancies in both mean climatology and event statistics exist in historical data products representing the same time period.
% \item Finer temporal data and more frequent atmosphere-land surface coupling increase the number of flagged events.
% \end{keypoints}

%% ------------------------------------------------------------------------ %%
%
%  ABSTRACT and PLAIN LANGUAGE SUMMARY
%
% A good Abstract will begin with a short description of the problem
% being addressed, briefly describe the new data or analyses, then
% briefly states the main conclusion(s) and how they are supported and
% uncertainties.

% The Plain Language Summary should be written for a broad audience,
% including journalists and the science-interested public, that will not have
% a background in your field.
%
% A Plain Language Summary is required in GRL, JGR: Planets, JGR: Biogeosciences,
% JGR: Oceans, G-Cubed, Reviews of Geophysics, and JAMES.
% see http://sharingscience.agu.org/creating-plain-language-summary/)
%
%% ------------------------------------------------------------------------ %%

%% \begin{abstract} starts the second page

% CMZ, assuming 5 figures/tables, we have 3500 to work with!

% The formula for PU = number of words/500 + number of figures + number of tables. Articles exceeding a certain amount of PUs incur excess page fees.
%
%Word count includes abstract, acknowledgements, text (and in-text citations), figure captions, table captions, and appendices. Equations count as one word no matter the size. Equations are not copyedited.
%
%Word count excludes title, author list and affiliations, key words, key points, plain language summary, table text, open research section, references, and supporting information. Supporting information is not copyedited.

\begin{abstract}
Rain-on-snow (RoS) events in regions of ephemeral snowpack -- such as the northeastern United States -- can be key drivers of cool-season flooding. We provide an automated algorithm for detecting rain-on-snow events in gridded climate data by generating an area-averaged time-series and then searching for periods of concurrent precipitation, surface runoff, and snowmelt exceeding pre-defined thresholds. When evaluated using historical data over the Susquehanna River Basin (SRB), the technique credibly finds RoS events in published literature and flags events that are followed by anomalously high streamflow as measured by gage data along the river. When comparing four different datasets representing the same 21-year period, we find large differences in RoS event magnitude and frequency, primarily driven by differences in estimated surface runoff and snowmelt. Using dataset-specific thresholds improves agreement between datasets somewhat but does not account for all discrepancies. We speculate that factors such as reanalysis model coupling frequency, choice of land surface model and meteorological forcing all play roles in how data products capture these compound extremes and suggest care is to be taken when climate datasets are used by stakeholders for operational decision-making.
\end{abstract}

% \section*{Plain Language Summary}
% {\color{blue} Colin will write something here when submitting, not included in word count!}

%%% STUFF TO ADD
% Comment about how RoS is a compound extreme + cite Kai's paper
% Add what variables in E3SM were nudged + provide namelists in final repo.

%% ------------------------------------------------------------------------ %%
%
%  TEXT
%
%% ------------------------------------------------------------------------ %%

%%% Suggested section heads:
% \section{Introduction}
%
% The main text should start with an introduction. Except for short
% manuscripts (such as comments and replies), the text should be divided
% into sections, each with its own heading.

% Headings should be sentence fragments and do not begin with a
% lowercase letter or number. Examples of good headings are:

% \section{Materials and Methods}
% Here is text on Materials and Methods.
%
% \subsection{A descriptive heading about methods}
% More about Methods.
%
% \section{Data} (Or section title might be a descriptive heading about data)
%
% \section{Results} (Or section title might be a descriptive heading about the
% results)
%
% \section{Conclusions}


\introduction

Rain-on-snow (RoS) events have been increasingly studied over the past few decades, yet overwhelmingly focused on mountainous regions \citep{singh1997hydrological,mccabe2007rain,wayand2015modeling,sterle2019hydroclimate,musselman2018projected,poschlod2020climate,siirila2021a,heggli2022toward,yu2022diverse,brandt2022a,maina2023diverging,haleakala2023watershed}.

Correspondingly, there has been less focus in areas with more ephemeral snow cover, such as the northeastern United States (US), even though these compound events are key drivers of `slow-rise' flooding -- floods generally occurring more than six hours after the onset of the meteorological driver \citep{dougherty2021high}.
Climatologically, RoS events in the northeastern US peak in late winter and spring \citep{ashley2008flood,villarini2010flood,dougherty2019climatology,wachowicz2020rain} and are a key driver of flooding in New England and the Atlantic side of Canada \citep{collins2014annual}.
Synoptic case study analyses of recent RoS events in the mid-Atlantic region demonstrate inland-running extratropical cyclones that advect warm, moist air as key dynamical players \citep{grote2021synoptic}.
Rapid snow ablation in ephemeral snow regions has been shown to have a strong correlation with increases in basin streamflow in the days following snowmelt \citep{suriano2020discharge}.

While climatological studies are critically important, event-level analysis has become increasingly important when communicating climate risks \citep{shepherd2018storylines}.
One basin in the northeastern US that has historically dealt with RoS events is the Susquehanna River Basin (SRB).
The most consequential non-tropical-cyclone flood in recent SRB history was an RoS flood that occurred in January 1996, resulting in $\sim$\$1.5 billion in damages and 30 fatalities \citep{leathers1998severe}.
Approximately four million people live within the SRB \citep{leathers2008hydroclimatic} despite it being climatologically flood-prone due to the wide variety of weather phenomena that occur within the region \citep{perry2000significant}.
Significant events such as this are frequently used by stakeholders as a point of reference for real-time forecasts and long-term planning \citep{george2019the}.
While these events are important for planning purposes, for larger scale climatological studies it is desirable to be able to identify such events in both observational datasets and model simulations.  Unfortunately,  quantifying extreme, compound, and discrete events in climate data sets is  a complex challenge, particularly because such datasets that are not developed specifically for this purpose and there is typically a  a lack of observational reference datasets to quantify their fidelity.
Gridded datasets (spatiotemporally continuous data provided on a regular latitude-longitude grid) of the historical record are frequently used to assess hydrometerological extremes in locations with poor or non-existent station observations and climate analyses requiring multiple complex variables.
They are also used to evaluate model sensitivity and performance.
Further, future changes in RoS event frequency and character due to climate change are projected via the use of models, which operate on numerical grids and don't have an a priori station record to compare to, making the evaluation of such events algorithmically a requirement.
To extract information regarding compound hydrometeorological extremes, such as RoS events, and their corresponding statistics, algorithmic techniques which objectively analyze datasets without manual intervention are desirable.
Here, we demonstrate a technique for generating an RoS event database at the basin scale for arbitrary gridded datasets and intercompare key decision-relevant differences (e.g., flood frequency) across four climate data products.
We choose to focus on the SRB based on proximity to major population centers and the aforementioned extreme event, although the technique described can be applied to any sufficiently defined basin, although regional thresholding may need to be applied.

%We focus on the direct prediction of coupled surface processes (i.e., snow water equivalent and surface runoff) to minimize issues with statistical or dynamical downscaling and permit a like-to-like comparison between different datasets.

\section{Methods}

\subsection{Datasets}

We evaluate RoS events within three widely-used climate datasets and in one state-of-the-art Earth system model (ESM) nudged towards an atmospheric reanalysis product.
All four datasets seek to reproduce observed conditions, although each uses a distinct methodology to do so.
First, we investigate the dataset described in \citet{livneh2015spatially} (L15).
L15 is a 1/16\degree{} hydrometeorological dataset covering most of North America.
Meteorological data provided by L15 consists of daily precipitation, temperature (maximum and minimum), and wind speed at each location \citep{henn2018an}.
This data is then temporally interpolated to obtain subdaily estimates \citep{bohn2013global}, which are then used to drive the Variable Infiltration Capacity (VIC, \citet{liang1994simple}) model to produce hydrometeorological outputs.
Next, we investigate the 1/8\degree{} North American Land Data Assimilation System (NLDAS-VIC4.0.5)  described in \citet{xia2012continental1}.
NLDAS is driven by offline atmospheric forcing derived from the North American Regional Reanalysis, with adjustments made to some variables based on observations.
NLDAS uses a combination of daily precipitation observations and radar data to produce hourly estimates.
While there are four NLDAS-2 land surface models (LSMs) that produce hydrologic output variables, we analyze only the NLDAS-VIC4.0.5 as it is the most methodologically consistent with L15.
We also analyze a $\sim$0.5\degree{} global reanalysis (JRA-55, \citet{kobayashi2015jra55}), generated by running a prognostic ESM while assimilating observational data during integration.
Global reanalyses serve as a bridge between in-situ, but spatio-temporally unstructured, observational data and free-running climate models.
Finally, a $\sim$1\degree{} nudged version of the U.S. Department of Energy Energy Exascale Earth System Model (E3SM) model is analyzed. Assessing this dataset provides insight into the capability of ESMs used in climate assessments (e.g., the Coupled Model Intercomparison Project Phase 6 (CMIP6)) to capture observed hydrometeorological extreme events.
E3SM is analogous to the majority of climate models in CMIP6.
To constrain the large-scale meteorology in E3SM to match observed conditions, the E3SM simulation is nudged using 6-hourly fields from the ERA5 reanalysis \citep{hersbach2020era5}.
This nudging acts as a crude assimilation technique and is only applied in the free atmosphere.
E3SM, therefore, reproduces patterns of 500 hPa geopotential height and sea level pressure while simulating grid-scale processes relatively untethered by the nudging reanalysis product \citep{sun2019impact}.
E3SM is run on an unstructured cubed-sphere mesh and simulation output is remapped to a 1\degree{}x1\degree{} rectilinear grid using higher-order methods \citep{hill2004architecture}.

\subsection{Defining basin-scale events}

To identify RoS events, three variables are extracted over the SRB.
These include precipitation (PRECIP), snow water equivalent (SWE), and surface water runoff (ROF).
The 24-hour change in SWE from the previous day (dSWE) is calculated via a backward difference.
All data is standardized to daily average values (00Z to 00Z) by temporally averaging any sub-daily (e.g., hourly) data at each grid cell.

Grid cells that have at least 50\% of their area enclosed by the boundary of the SRB are kept, while those exterior to the SRB  are set to missing values.
The resulting domains for each product can be seen in Fig. \ref{fig:means}. A basin-wide time series is then constructed by spatially averaging fields for each day and smoothing the resulting time series using a moving average to reduce day-to-day noise.
We choose a 5-day window based on synoptic timescales \citep{holton2004introduction}, although different windows didn't materially change any findings.

RoS days are defined algorithmically by flagging periods of negative dSWE and positive ROF that both exceed specified thresholds in the smoothed time series.
Contiguous days are considered to be part of a single event such that events can last for different durations.
We test two methods of thresholding; one uses fixed thresholds across all four datasets (FIXED) and the other defines dataset-specific thresholds by those exceeding 95\% of all daily values (RELATIVE).
For FIXED, we require an average dSWE of -1.4 mm/day and ROF of 1.4 mm/day based on a manual sensitivity analysis.
Thresholds in the RELATIVE configuration are calculated independently for each dataset by setting the threshold to the 95\% value of its own 1985-2005 smoothed time series.
To enforce a criterion that precipitation occurs during at least some portion of the event, we require an average PRECIP of 2 mm/day, which is kept the same in both the FIXED and RELATIVE configurations.

For context, the definition of ROS is somewhat arbitrary. Most studies enforce some fixed combination of precipitation and snowpack threshold. \citet{ye2008winter} classified events as liquid precipitation falling onto at least 10 mm of existing snowpack in a gridbox. \citet{musselman2018projected} define `ROS days' where at least 10 mm of precipitation falls on at least 10 mm of snowpack in a given day. This technique was adopted by \citet{lopez2021changes} and \citet{maina2023diverging}. A similar strategy, but applying higher thresholds (20 mm precipitation, 250 mm snowpack), was used by \citet{wurzer2016influence}. Instead of a SWE metric, others have applied snow cover fraction or some other snow/no-snow classification in addition to a precipitation threshold \citep{mazurkiewicz2008assessing,pradhanang2013rain,cohen2015trends}.

Others include some measure of snowmelt, such as \citet{freudiger2014large} and \citet{li2019the} who required 3 mm of rainfall, 10 mm SWE, and a 20\% reduction in the snowpack (implied dSWE $<=$-20 mm/day). However, relative strategies have also been proposed, such as the 98\% threshold used for covarying extremes in the compound event analysis of \citet{poschlod2020climate}. Other studies simply just require the joint occurrence of precipitation and snowmelt in a given period \citep{mccabe2007rain,surfleet2013variability,collins2014annual,guan2016hydrometeorological,jeong2018rain}. \citet{wachowicz2020rain} used the same gridded data and explored four different definitions derived from some of the above and found high-level agreement.

This is not meant to be an exhaustive list but, rather, to rather to highlight that both ROS evaluation techniques in this manuscript fall within the scope of previously published strategies. It also emphasizes that extreme ROS events in mountainous regions with more seasonal snowpack or those using gridpoint values versus basin-integrated metrics may require more stringent thresholds. With the caveat that much of this work has focused on regions with less ephemeral snowpack (e.g., western U.S. mountains), the algorithm discussed here falls within the envelope of previously published work both from a heuristic perspective and also with respect to our defined thresholds.

To confirm all datasets adequately represent the same period, Pearson correlations of basin-wide statistics were statistically significant with a two-sided $t$-test between all permutations of daily time series (Table SX). This confirms that all datasets fundamentally simulate the same meteorology and land surface evolution as processed.

%Note that while the majority of the events are associated with PRECIP we do not include a specific criterion, but rather, leverage ROF as a proxy for surface flooding.

\section{Results}

\subsection{Climatology}

The average cool-season climatologies of PRECIP, SWE, ROF, and dSWE are shown in Figure \ref{fig:means}.
The higher resolution of L15 and NLDAS is evident from the added structure in the mean fields.
Mean PRECIP (Fig. \ref{fig:means}a-d) is higher in JRA and E3SM when compared to the L15 and NLDAS.
This may be due to factors such as atmospheric model biases or the inclusion of gauge data in L15 and NLDAS, although it has been shown that significant spread exists in historical gridded climate data products, even for more commonly observed variables such as PRECIP \citep{gutmann2012comparison,livneh2014filling,henn2018an}.
ROF (Figure \ref{fig:means}e-h) and SWE (Figure \ref{fig:means}i-l) climatologies differ between the data products.
Notably, L15 produces mean ROF values that are less than half of the climatologies of each of the other three datasets.
NLDAS produces less SWE climatologically, $<$20\% of the SWE produced by L15 or E3SM, and even less than the coarser JRA product.
It is well-known that simulated ROF from different hydrologic models can be extremely variable, with regional differences between products reaching an order of magnitude \citep{gudmundsson2012comparing,sood2015global,beck2017global}.
Previous work has also shown that SWE estimates can vary greatly across datasets \citep{lundquist2015high,Rhoades2018a}, particularly over the ephemeral snow area of the NEUS \citep{mccrary2017evaluation,mccrary2022projections}.
dSWE climatology is shown in Fig. \ref{fig:means}m-p.
When calculating the mean, all accumulation (or zero change) days are ignored to isolate snow loss days.
Here, NLDAS also exhibits the lowest magnitude of dSWE, although this may be due to the shallower mean snowpack.
More interestingly, the largest climatological dSWE magnitude is found in JRA, even though the SWE does not contain the largest depths, implying the snowpack is more variable in JRA and may be prone to more rapid snow loss (from a dSWE per unit time perspective).

We emphasize that, from a physical standpoint, differences in snowfall and snowmelt timing \citep{rauscher2008future,mccabe2005trends}, snow properties \citep{brown2006evaluation}, temperature and permeability of the soil \citep{niu2006effects}, precipitation type partitioning \citep{knowles2006trends}, and evapotranspiration \citep{zheng2019on} all can lead to differences in how these quantities are simulated.
We speculate that these mechanisms are playing important roles in the differing mean climatologies but performing a fully-detailed water budget analysis is beyond the scope of this analysis.

\subsection{Flagged event statistics}

Turning to the algorithmically flagged RoS events, Table \ref{table:means} shows summary statistics for all four data products.
Focusing on the FIXED thresholds, the number of events that occurred in the SRB over the 21-year study period varies by an order of magnitude, from 6 events in L15 to 58 in E3SM.
Interestingly, large differences don't necessarily appear when considering the mean event-averaged dSWE, ROF, or PRECIP.
In fact, when a RoS event occurs, L15 has the largest PRECIP and largest dSWE, although the smallest ROF.

When using the RELATIVE thresholds, the event frequencies agree better, with only a factor of two difference between L15/NLDAS and JRA/E3SM.
The number of events in L15 increases because the ROF threshold (95th percentile of daily values) is reduced from 1.4 to 0.6 mm/day.
Conversely, fewer events were classified in E3SM, due to increases in both the required ROF and dSWE thresholds applied to the daily climatology.
However, even when accounting for the baseline climatological differences of the data products by thresholding on percentiles, rather than absolute magnitudes, large differences still are evident in all metrics.

\begin{figure}
\begin{tabular}{c}
\includegraphics[width=0.98\linewidth]{{figs/cropped/climo_comp_panel_PRECIP}.pdf} \\
\includegraphics[width=0.98\linewidth]{{figs/cropped/climo_comp_panel_ROF}.pdf} \\
\includegraphics[width=0.98\linewidth]{{figs/cropped/climo_comp_panel_SWE}.pdf} \\
\includegraphics[width=0.98\linewidth]{{figs/cropped/climo_comp_panel_dSWE}.pdf}
\end{tabular}
\caption{November to April mean climatologies of L15, NLDAS, JRA, and E3SM (left to right). From top to bottom are precipitation (PRECIP; mm/day), surface runoff (ROF; mm/day), snow water equivalent (SWE; mm), and daily change in snow water equivalent (dSWE; mm/day). dSWE only includes days with snow loss at a particular grid cell. Data is only included if $>$50\% of a grid cell lies within the SRB bounds (black outline).}
\label{fig:means}
\end{figure}

\begin{table}
\resizebox{\textwidth}{!}{%
\begin{tabular}{lcccccccc}
      & wt\_rof & st\_swe & pt\_pre & Events & Duration & dSWE & ROF & PRECIP \\
L15   & 1.4     & 1.4     & 2.0     & 6   & 3.2          & 5.3          & 1.5            & 9.5            \\
NLDAS & 1.4     & 1.4     & 2.0     & 16  & 2.9          & 5.2          & 2.1            & 6.3            \\
JRA   & 1.4     & 1.4     & 2.0     & 48  & 3.5          & 4.4          & 2.6            & 5.3            \\
E3SM  & 1.4     & 1.4     & 2.0     & 58  & 4.1          & 5.2          & 2.4            & 6.5            \\
      &         &         &         &     &              &              &                &                \\
L15   & 0.6     & 1.5     & 2.0     & 20  & 5.2          & 5.3          & 1.1            & 6.2            \\
NLDAS & 1.4     & 0.8     & 2.0     & 20  & 2.8          & 4.2          & 2.1            & 7.2            \\
JRA   & 1.6     & 1.9     & 2.0     & 40  & 3.2          & 4.1          & 2.5            & 5.1            \\
E3SM  & 1.8     & 2.2     & 2.0     & 41  & 4.1          & 8.0          & 2.9            & 6.9
\end{tabular}
}
\caption{Statistics of RoS events over the SRB using FIXED thresholds (top) and RELATIVE thresholds (bottom). ROF$_t$, dSWE$_t$, and PRECIP$_t$ represent the thresholds used (mm/day). Events represent the number of RoS events flagged over the 1980-2005 period. Duration is the average number of consecutive days an RoS event lasts. dSWE, ROF, and PRECIP represent the average snow loss, amount of runoff rate, and amount of precipitation rate (mm/day) per event by calculating the mean daily value for each individual event and then averaging those.}
\label{table:means}
\end{table}

The differences across gridded climate data products are also shown in Fig. \ref{fig:histograms}.
All plot subpanels show statistics using RELATIVE, although the same figures for FIXED are shown in the Supplementary Material.
Figure \ref{fig:histograms}a shows the total number of RoS events flagged over the climatological period (fourth column of Table \ref{table:means}), while Figs. \ref{fig:histograms}b-d show the frequency distribution for basin-averaged maximum rates of PRECIP, ROF, and dSWE at the event level. These are calculated by selecting the maximum daily value from the array of actual (i.e., unsmoothed) daily values during each RoS event.

The maximum PRECIP associated with flagged RoS events is similar between the four datasets, with E3SM tending to have slightly more extreme PRECIP occurring over the SRB (in agreement with Figure \ref{fig:means}).
Larger differences are seen in ROF and dSWE.
In ROF, both the E3SM and JRA datasets produce larger event magnitudes of ROF, and subsequently have longer tails in their probability distributions, compared to the other two datasets.
L15 produces RoS events with the least ROF (averaging approximately one-third of those found in either E3SM or JRA), with NLDAS in between the other three.
The probability distribution functions of dSWE highlight an even more complex picture, with both NLDAS and L15 having narrower distributions with smaller magnitudes.
Of note, JRA and E3SM have broader distributions (i.e., longer tails) but the JRA distribution is more skewed, with frequent low dSWE events whereas E3SM has a more uniform distribution of dSWE rates.

In summary, using either a relative or fixed threshold to identify RoS events, the fully-coupled ESMs (E3SM and JRA) produce more events than L15 and NLDAS.
While daily PRECIP in each product differs somewhat, it should be noted that these differences are relatively small.
Rather, the majority of the differences in RoS events flagged arise from lower magnitudes of ROF (dSWE) in the L15 (NLDAS).
It is worth noting that L15 and NLDAS produce fewer RoS events regardless of which thresholding technique is used, so not only are the distributions of relevant daily variables shifted relative to the other models, but their skewness is impacted as well (Fig. \ref{fig:histograms}).

\begin{figure}
\begin{tabular}{cc}
\includegraphics[width=0.442\linewidth]{{figs/cropped/events_95}.pdf} & \includegraphics[width=0.451\linewidth]{{figs/cropped/Max_precip_95}.pdf} \\
\includegraphics[width=0.451\linewidth]{{figs/cropped/Max_runoff_95}.pdf} & \includegraphics[width=0.451\linewidth]{{figs/cropped/Max_dSWE_95}.pdf}
\end{tabular}
\caption{Histogram statistics for RoS events within the RELATIVE detection framework. The number of RoS events for each product from 1985-2005 is shown in the top left. The other three panels show frequency distributions of the daily rate (mm/day) of maximum precipitation (PRECIP), maximum runoff (ROF), and maximum change in SWE (dSWE, snowmelt positive).}
\label{fig:histograms}
\end{figure}

\subsection{Single-year evaluation}

\begin{figure}
\begin{tabular}{cc}
\includegraphics[width=0.45\linewidth]{{figs/cropped/L15_1995_events}.pdf} & \includegraphics[width=0.45\linewidth]{{figs/cropped/NLDAS_1995_events}.pdf} \\
\includegraphics[width=0.45\linewidth]{{figs/cropped/JRA_1995_events}.pdf} & \includegraphics[width=0.45\linewidth]{{figs/cropped/E3SM_1995_events}.pdf}
\end{tabular}
\caption{Time series of daily precipitation (green), surface runoff (orange), and snow loss (pink) during WY95 for each of the four products. Vertical purple shading denotes periods flagged as a rain-on-snow event. At the top of each time series are colored bars which denote extreme values (greater than 75\%) of observed USGS streamflow at Harrisburg, with very dark hues representing 99\% values over the 1980-2005 period.}
\label{fig:yr-timeseries-comp}
\end{figure}

\begin{figure}
\begin{tabular}{cc}
\includegraphics[width=0.45\linewidth]{{figs/cropped/L15_1995_scatplot}.pdf} & \includegraphics[width=0.45\linewidth]{{figs/cropped/NLDAS_1995_scatplot}.pdf} \\
\includegraphics[width=0.45\linewidth]{{figs/cropped/JRA_1995_scatplot}.pdf} & \includegraphics[width=0.45\linewidth]{{figs/cropped/E3SM_1995_scatplot}.pdf}
\end{tabular}
\caption{Bubble plots comparing precipitation (y-axis), SWE change (x-axis), and surface runoff (size of bubble) for each of the four datasets during WY95. For each bubble, the values come from the same calendar day. Filled bubbles were flagged by the algorithm as a rain-on-snow event (purple shaded periods in Fig. \ref{fig:yr-timeseries-comp}).}
\label{fig:bubble-comp}
\end{figure}

% \begin{figure}
% \centering
% \begin{tabularx}{\textwidth}{XX}
% \includegraphics[width=1.0\linewidth]{{figs/cropped/L15_1995_events}.pdf} & \includegraphics[width=0.75\linewidth]{{figs/cropped/L15_1995_scatplot}.pdf} \\ \includegraphics[width=1.0\linewidth]{{figs/cropped/NLDAS_1995_events}.pdf} & \includegraphics[width=0.75\linewidth]{{figs/cropped/NLDAS_1995_scatplot}.pdf} \\
%     \includegraphics[width=1.0\linewidth]{{figs/cropped/JRA_1995_events}.pdf} & \includegraphics[width=0.75\linewidth]{{figs/cropped/JRA_1995_scatplot}.pdf} \\\includegraphics[width=1.0\linewidth]{{figs/cropped/E3SM_1995_events}.pdf} & \includegraphics[width=0.75\linewidth]{{figs/cropped/E3SM_1995_scatplot}.pdf}
% \end{tabularx}
% \caption{(left) Time series of daily precipitation (PRECIP; green), surface runoff (ROF; orange), and change in SWE (dSWE; pink) during WY95 for each dataset. Vertical purple shading denotes periods flagged as a rain-on-snow (RoS) event using frameworks discussed in the Methods. Along the top x-axis of each time series is a colored bar series that denotes extreme values (greater than 75\%) of observed USGS streamflow at Harrisburg, PA with the darkest hues representing 99\% values over the 1980-2005 period. (right) Bubble plots comparing daily PRECIP (y-axis), dSWE (x-axis), and ROF (size of bubble) during WY95. Bubbles that are filled were days flagged by the RoS algorithm as occurring during an RoS event.}
% \label{fig:merged-wy}
% \end{figure}

To further explore RoS events at a more granular level we focus on results associated with the 1995 water year (WY95, October 1995 to September 1996).
We choose this WY since this includes the 1996 SRB flood that is often used in water management circles for disaster planning purposes (personal communication from HyperFACETS stakeholders, see also \citet{jagannathan2021the}).
The same visualizations for other WYs are shown in the Supplemental Material.

Figure \ref{fig:yr-timeseries-comp} shows the daily WY95 time series of basin-integrated PRECIP, ROF, and dSWE.
Negative (positive) dSWE denotes snowmelt (accumulation).
Vertical shading denotes RoS events that were flagged by the algorithm.
At the top of each panel is a stripe with four different shadings, representing days where streamflow exceeded 75\%, 90\%, 95\%, and 99\% relative over the 1985-2005 period at the US Geological Survey (USGS) gage at Harrisburg, Pennsylvania (USGS \#01570500), with darker colors representing anomalously high flow conditions.

The January 17-18, 1996 event is readily apparent for three of the four data products (NLDAS, JRA, and E3SM).
Observed streamflow spiked during and immediately after the RoS event as shown by the dark blue stripes at the top of each time series, indicating a lag between when the RoS event algorithm identifies changes in PRECIP, dSWE, and ROF and the observed daily streamflow gage observation at Harrisburg, PA (namely, the 99th percentile streamflow exceedance).
While this is operationally the largest RoS event observed over the period, there remain large discrepancies between the datasets.
The dSWE signal is largest in magnitude within JRA and E3SM compared to NLDAS.
L15 shows a very minimal dSWE, to the point that the RoS event thresholds are not triggered in the detection algorithm.
PRECIP is more similar across the three datasets, implying that the reduced ROF in L15 is likely due to the lack of snowmelt.

All products also indicate a second, more moderate RoS event during the last third of February, although L15 and E3SM (JRA and E3SM) show larger dSWE (ROF) signals than the other two datasets.
The USGS streamflow also exceeded the 95th percentile for this RoS event.
More moderate flooding also appeared to occur in March and April although the detection algorithm only flagged an event in L15 and E3SM.
Since all RoS events flagged by the detection algorithm result in well-above-average streamflow, this highlights the efficacy of the detection algorithm in capturing meaningful hydrometeorological extremes.

Another way to visualize the WY95 RoS events is shown in Figure \ref{fig:bubble-comp}.
This plot shows the daily distribution of all three hydrometeorological quantities that make up a rain-on-snow event by plotting dSWE on the x-axis, PRECIP on the y-axis, and the size of the x-y marker depicts the magnitude of ROF.
Markers are filled if the RoS event criteria are satisfied for that calendar day and are colored red (blue) if there is dSWE loss (gain).
The variability of the PRECIP (y-axis) is the most similar between the two ESMs.
The vast majority of daily basin-scale precipitation remains below 30 mm/day, although E3SM produces a few days with more extreme precipitation rates.
Larger differences across datasets are noted for the other two RoS event response variables.
JRA and E3SM produce a wide spread in both RoS and non-RoS events along the y-axis, indicating that the ESMs produce days with the largest magnitudes of dSWE.
Further, L15 has markers that are small in size, indicating low daily ROF magnitudes when compared to the other three products.
There is a substantial spread across the four datasets, even over comparable time series with well-defined and record-setting RoS events.
This is likely due to daily differences in the timing of storms, the amount of water vapor transport and precipitation they produce, and how close surface air temperatures are to freezing conditions that in turn influence if a meteorological event leads to an increase in snow accumulation or results in an RoS event.

\subsection{Evaluation of a single event}

\begin{figure}
\noindent\includegraphics[width=0.95\textwidth]{figs/cropped/merged_SWE_1995.png}
\caption{Daily SWE timeseries averaged over the SRB during WY95 for all four data products. Shaded in blue are the same events from Fig. \ref{fig:yr-timeseries-comp}.}
\label{fig:allswewy95}
\end{figure}

% \begin{figure}
% \begin{tabular}{cc}
% \includegraphics[width=0.45\linewidth]{{figs/cropped/L15_1995_scatplot}.pdf} & \includegraphics[width=0.45\linewidth]{{figs/cropped/NLDAS_1995_scatplot}.pdf} \\
% \includegraphics[width=0.45\linewidth]{{figs/cropped/JRA_1995_scatplot}.pdf} & \includegraphics[width=0.45\linewidth]{{figs/cropped/E3SM_1995_scatplot}.pdf}
% \end{tabular}
% \caption{....}
% \label{fig:allswewy95}
% \end{figure}

One notable question given the above analysis is why the January 1996 event is captured differently across the products, particularly why it is `missed' by the L15 dataset.
To confirm, Fig. \ref{fig:allswewy95} shows the evolution of total on-surface SWE over WY95 for all datasets.
All products show increasing SWE from mid-December onwards, albeit with varying accumulation rates and maximum depths.
The datasets most differ in the SWE ablation during mid-January, with L15 showing essentially no ablation of the existing snowpack, JRA showing near total ablation, and E3SM and NLDAS in between the two extremes.

To untangle the potential source of this discrepancy, Fig. \ref{fig:1996eventtrace} shows the temperature trace (red line, right axis) at the grid cell nearest Harrisburg, PA for the four products during the 1996 event.
Also included is the temperature trace observed at Harrisburg, PA (thin blue line) along with a reference freezing line (black).
The product-specific associated precipitation rate (mm/hr) partitioned into rain (green) and snow (cyan) is denoted by bars (left axis).

%https://journals.ametsoc.org/view/journals/clim/26/23/jcli-d-12-00508.1.xml
%http://livnehpublicstorage.colorado.edu:81/Livneh.2013.CONUS.Dataset/

\begin{figure}
\noindent\includegraphics[width=0.75\textwidth]{figs/cropped/precip_vs_t_1996.pdf}
\caption{Evolution of reference height surface air temperature and precipitation during the January 1996 SRB RoS flood event across data products. Data is taken from the grid cell nearest to Harrisburg, PA. The left axis corresponds to the precipitation rate (shown in bars from the bottom) reported by the product. Green bars indicate rainfall (precipitation occurring when $T_s > 0$\degree{}C) and cyan bars indicate snowfall (precipitation occurring when $T_s <= 0$\degree{}C). The right axis shows reference height surface air temperature as denoted by the red line, with a thick black horizontal line representing 0\degree{}C (273.15 K). The thin blue line on each panel represents the observed temperature trace at Harrisburg, PA over the period.}
\label{fig:1996eventtrace}
\end{figure}

None of the four products precisely match the temperature trace, although we acknowledge that this is, at least, partly due to the resolution of the data.
While the timing of the temperature increase is well matched in E3SM and NLDAS, both products have a slight cool bias during the warm air advection component of the event.
The overall temperature maximum is better matched by JRA, although the peak occurs approximately 6 hours earlier than in observations. An opposite shift is seen in L15 data, with the observed temperature peak leading L15 by approximately 6 hours.

Over all four datasets, only L15 reports below-freezing temperatures between January 18th at 12Z and January 19th at 18Z.
This is likely because L15 only leverages daily minimum and maximum observed temperatures to construct temperature fields.
At each L15 grid cell, temperature minima and maxima are assumed to occur at sunrise and approximately late afternoon, respectively, with an interpolation spline used to provide information at intermediate hours \citep{bohn2013global}.
These temperatures are always assumed to occur on the day of record \citep{livneh2015spatially}, which is relevant because the actual temperature minimum on January 19th occurred during the local afternoon into the evening after the passage of a cold front \citep{leathers1998severe}.
For this event, the diurnal cycle of temperature is therefore more strongly influenced by atmospheric dynamics than solar insolation.

To understand how this could impact snowpack metamorphism, we investigate precipitation during the event.
We can assume precipitation type at the surface is determined by whether the reference height surface air temperature is above or below freezing, which is the manner in which the majority of land surface models partition precipitation \citep{harpold2017rain,jennings2018spatial,Woodburn2021}.
Since L15 contains below-freezing temperatures between 00Z and 12Z on January 19, it is the only product that partially partitions precipitation into the frozen state.
Further, since daily precipitation is evenly partitioned into sub-daily bins to then force VIC, L15 registers more precipitation during this period than the other products due to a peak later in the day.

This motivates the following interpretation.
In L15, snowpack lost due to melt during the above-freezing temperatures during the 1996 event is, at least, partially offset by new snow on the ground that falls during the event due to below-freezing temperatures.
These below-freezing periods also mitigate any snowmelt in the land surface model that would be associated with enthalpy fluxes intothe existing snowpack.
When combined, this explains the lack of a decline in SWE in Fig. \ref{fig:allswewy95}.
All other datasets show a more prolonged period of above-freezing temperatures during the window noted above, with all precipitation during this period falling as rain versus snow.
This induced varying degrees of snowmelt in E3SM, NLDAS, and JRA that are sufficient to trigger the RoS detection algorithm.

\conclusions

We interrogate four different gridded climate data products, that include PRECIP, ROF, and SWE, in order to quantify differences in the representation of coupled land-atmosphere processes that lead to flooding events in the historical record.
In particular, we focus on RoS floods over the SRB and devise an algorithm for the automatic detection of RoS events that can be applied to any dataset.

Detection algorithm flagging for times of collocated ROF and dSWE does a reasonable job of marking periods that will be followed by above-normal streamflow.
We find using fixed thresholds for RoS-relevant variables applied uniformly across multiple gridded datasets leads to large discrepancies in event frequency over the historical period, up to a factor of 10.

Normalizing these thresholds by each dataset's climatology (relative thresholds based on daily percentiles) improves agreement.
However, there remains approximately a factor of two difference between event counts, implying that the underlying distributions are fundamentally different in both shape and magnitude across the data analyzed.

% Notably, although we refer to automated algorithm-flagged events as RoS events, there is no explicit PRECIP threshold.
% With that said, we find that 75\% of automated algorithm-flagged events have at least one day of $>5$ mm/day of basin-averaged precipitation and 95\% have at least one day of measurable precipitation ($>$1 mm/day).
% This implies that while ablation-only snowmelt events can lead to flooding, the vast majority of events producing large flood signals involve some form of precipitation as well.

%A common misconception is that RoS events are generated by warm rain transferring heat to the snowpack which then ripens or ablates it.

This underscores the complex assessment of such flood events. Multiple studies have found that the actual heat transfer between the liquid rain and the surface of the snowpack is rather small and explains only a small fraction of the observed snowmelt \citep{moore1984controls}.
Rather, factors such as surface humidity and temperature (and associated latent and sensible heat fluxes) and downwelling radiation into the snowpack are more dominant drivers of snow ablation \citep{mazurkiewicz2008assessing,wurzer2016influence,harpold2018humidity}.
It is evident that similar synoptic meteorological patterns \citep{grote2021synoptic} and additional liquid input to the surface (i.e., runoff being a combination of snowmelt and water flux from the atmosphere) leads to the majority of RoS events being associated with, at least, some precipitation.

The spatiotemporal dependencies of how meteorological data is generated for land surface and/or hydrological model forcing are critically important.
While spatial resolution of data is important, particularly for snow processes in complex terrain \citep{henn2018an,Woodburn2021}, we show that the time resolution of data is just as critical for transient extremes, such as RoS events.
This is because the timing of synoptic variations in reference height surface air temperature and humidity that dictate snowmelt and precipitation phase can occur on the order of hours at local scales and can have an outsized role in compound extreme event representation if those variations are threshold-dependent (e.g., storm rain-snow partitioning and alterations to the freezing line at the land surface).

Since RoS events in regions of ephemeral snow (e.g., SRB) can have rapid changes in surface forcing at hourly timescales (e.g., \citet{leathers1998severe}), temporally coarse data to force offline land surface models may result in an underprediction of RoS frequency.
This may occur if time-interpolated data (and less frequent coupling) smooths and/or clips out short-term extrema and results in mismatched forcing or reduced day-to-day variability of multiple, co-dependent anomalies (e.g., temperature and precipitation extremes) required to accurately simulate historical, decision-relevant hydrometeorological extremes (e.g., 1996 SRB RoS event). We note that this effect can be independent of the model timestep itself. For example, the L15 data disaggregates precipitation data across sub-daily timesteps. While the land surface model used is integrating at smaller timescales, the effective time resolution of the forcing data remains daily.

We also show that even though a dataset is provided at much coarser spatial resolutions than is desired (e.g., JRA and E3SM), model-derived datasets that are more frequently coupled and/or constrained at shorter timescales (e.g., reanalysis products and nudged ESMs) may produce more accurate land-atmosphere interactions and better representation of decision-relevant hydrometeorological extremes.

It is recommended that gridded climate data developers consider the temporal resolution of land surface forcing if the representation of such daily hydrometeorological extrema is desirable, particularly from a use-inspired or decision-relevant context \citep{Jagannathan2021}.
While we do not downscale any datasets in this study, it is likely that using different meteorological data to force the same land surface and/or hydrological model will result in vastly different predicted streamflows, particularly for RoS events when variables are spatiotemporally co-dependent and would be sensitive to any post-processing adjustments (e.g., mean climatological correction).

From a stakeholder perspective, this is an important consideration when back-testing models, and, in particular, applying such models to evaluate tail risks (e.g., 1-in-100-year flood events and how they may change in a future climate).
The results here show longer tails in the fully-coupled ESM-derived climate data, which may impact return rates of extreme events, even if calibrated.
Therefore, care must be taken when applying data requiring coupling between the atmosphere and land surface (and riverine) components, whether generated dynamically or statistically.
While post-processing adjustments to the mean climatology may be desirable, these adjustments can alter decision-relevant hydrometeorological extremes that reside in the tail of the distribution.



%%

%  Numbered lines in equations:
%  To add line numbers to lines in equations,
%  \begin{linenomath*}
%  \begin{equation}
%  \end{equation}
%  \end{linenomath*}



%% Enter Figures and Tables near as possible to where they are first mentioned:
%
% DO NOT USE \psfrag or \subfigure commands.
%
% Figure captions go below the figure.
% Table titles go above tables;  other caption information
%  should be placed in last line of the table, using
% \multicolumn2l{$^a$ This is a table note.}
%
%----------------
% EXAMPLE FIGURES
%
% \begin{figure}
% \includegraphics{example.png}
% \caption{caption}
% \end{figure}
%
% Giving latex a width will help it to scale the figure properly. A simple trick is to use \textwidth. Try this if large figures run off the side of the page.
% \begin{figure}
% \noindent\includegraphics[width=\textwidth]{anothersample.png}
%\caption{caption}
%\label{pngfiguresample}
%\end{figure}
%
%
% If you get an error about an unknown bounding box, try specifying the width and height of the figure with the natwidth and natheight options. This is common when trying to add a PDF figure without pdflatex.
% \begin{figure}
% \noindent\includegraphics[natwidth=800px,natheight=600px]{samplefigure.pdf}
%\caption{caption}
%\label{pdffiguresample}
%\end{figure}
%
%
% PDFLatex does not seem to be able to process EPS figures. You may want to try the epstopdf package.
%

%
% ---------------
% EXAMPLE TABLE
%
% \begin{table}
% \caption{Time of the Transition Between Phase 1 and Phase 2$^{a}$}
% \centering
% \begin{tabular}{l c}
% \hline
%  Run  & Time (min)  \\
% \hline
%   $l1$  & 260   \\
%   $l2$  & 300   \\
%   $l3$  & 340   \\
%   $h1$  & 270   \\
%   $h2$  & 250   \\
%   $h3$  & 380   \\
%   $r1$  & 370   \\
%   $r2$  & 390   \\
% \hline
% \multicolumn{2}{l}{$^{a}$Footnote text here.}
% \end{tabular}
% \end{table}

%% SIDEWAYS FIGURE and TABLE
% AGU prefers the use of {sidewaystable} over {landscapetable} as it causes fewer problems.
%
% \begin{sidewaysfigure}
% \includegraphics[width=20pc]{figsamp}
% \caption{caption here}
% \label{newfig}
% \end{sidewaysfigure}
%
%  \begin{sidewaystable}
%  \caption{Caption here}
% \label{tab:signif_gap_clos}
%  \begin{tabular}{ccc}
% one&two&three\\
% four&five&six
%  \end{tabular}
%  \end{sidewaystable}

%% If using numbered lines, please surround equations with \begin{linenomath*}...\end{linenomath*}
%\begin{linenomath*}
%\begin{equation}
%y|{f} \sim g(m, \sigma),
%\end{equation}
%\end{linenomath*}

%%% End of body of article

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Optional Appendix goes here
%
% The \appendix command resets counters and redefines section heads
%
% After typing \appendix
%
%\section{Here Is Appendix Title}
% will show
% A: Here Is Appendix Title
%
%\appendix
%\section{Here is a sample appendix}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% Optional Glossary, Notation or Acronym section goes here:
%
%%%%%%%%%%%%%%
% Glossary is only allowed in Reviews of Geophysics
%  \begin{glossary}
%  \term{Term}
%   Term Definition here
%  \term{Term}
%   Term Definition here
%  \term{Term}
%   Term Definition here
%  \end{glossary}

%
%%%%%%%%%%%%%%
% Acronyms
%   \begin{acronyms}
%   \acro{Acronym}
%   Definition here
%   \acro{EMOS}
%   Ensemble model output statistics
%   \acro{ECMWF}
%   Centre for Medium-Range Weather Forecasts
%   \end{acronyms}

%
%%%%%%%%%%%%%%
% Notation
%   \begin{notation}
%   \notation{$a+b$} Notation Definition here
%   \notation{$e=mc^2$}
%   Equation in German-born physicist Albert Einstein's theory of special
%  relativity that showed that the increased relativistic mass ($m$) of a
%  body comes from the energy of motion of the bodythat is, its kinetic
%  energy ($E$)divided by the speed of light squared ($c^2$).
%   \end{notation}


\codedataavailability{
L15 data was downloaded from the National Oceanic and Atmospheric Administration Physical Science Laboratory, available at \url{https://psl.noaa.gov/data/gridded/data.livneh.html}. NLDAS-VIC4.0.5 data was downloaded from NCEP, available at \url{ftp://ldas.ncep.noaa.gov/nldas2/retrospective/vic4.0.5}. JRA-55 data was downloaded from the Research Data Archive at the National Center for Atmospheric Research, Computational and Information Systems Laboratory, available at \url{https://doi.org/10.5065/D6HH6H41}. The version of E3SM run here was v2.0.0-alpha.2-1816-gf9cbe57a2 and is available at https://github.com/E3SM-Project/E3SM. ERA5 data used to nudge the E3SM solution was downloaded from the Copernicus Climate Data Store (CDS), available at \url{https://www.ecmwf.int/en/forecasts/datasets/reanalysis-datasets/era5}. Station data for Harrisburg, PA was acquired from the Iowa Environmental Mesonet at \url{https://mesonet.agron.iastate.edu/}. The SRB is defined using a shapefile provided by the SRB Commission (\url{https://www.srbc.net/portals/susquehanna-atlas/data-and-maps/subbasins/index.html}). All data and scripts used to generate the figures contained in this manuscript are currently available at \url{xxxxxx} and will be uploaded to Zenodo, given a DOI, and linked [here] upon acceptance.
}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%  ACKNOWLEDGMENTS
%
% The acknowledgments must list:
%
% >>>>	A statement that indicates to the reader where the data
% 	supporting the conclusions can be obtained (for example, in the
% 	references, tables, supporting information, and other databases).
%
% 	All funding sources related to this work from all authors
%
% 	Any real or perceived financial conflicts of interests for any
%	author
%
% 	Other affiliations for any author that may be perceived as
% 	having a conflict of interest with respect to the results of this
% 	paper.
%
%
% It is also the appropriate place to thank colleagues and other contributors.
% AGU does not normally allow dedications.

\authorcontribution{CZ devised the project and led the writing of the manuscript, with input from RM and AR. BA post-processed climate data and wrote the majority of the RoS detection algorithm. AR performed an initial cursory analysis and devised the bubble plot visualization.} %% this section is mandatory

\competinginterests{The authors declare no competing interests.} %% this section is mandatory even if you declare that no competing interests are present

%\disclaimer{TEXT} %% optional section

\begin{acknowledgements}
This work is supported by the U.S. Department of Energy (DOE), Office of Science, Office of Biological and Environmental Research program under Award DE-SC0016605 ``A framework for improving analysis and modeling of Earth system and intersectoral dynamics at regional scales.'' Data acquisition and E3SM simulations were completed at the DOE National Energy Research Scientific Computing Center (NERSC) at Lawrence Berkeley National Laboratory (DE-AC02-05CH11231) using NERSC award ERCAP0020801. Event algorithm development, calibration, and analysis was performed on the Pennsylvania State University's Institute for Computational and Data Sciences' Roar supercomputer.
\end{acknowledgements}

%% ------------------------------------------------------------------------ %%
%% References and Citations

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% \bibliography{<name of your .bib file>} don't specify the file extension
%
% don't specify bibliographystyle
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\bibliographystyle{copernicus}
\bibliography{refs-ros-metrics.bib}

%Reference citation instructions and examples:
%
% Please use ONLY \cite and \citeA for reference citations.
% \cite for parenthetical references
% ...as shown in recent studies (Simpson et al., 2019)
% \citeA for in-text citations
% ...Simpson et al. (2019) have shown...
%
%
%...as shown by \citeA{jskilby}.
%...as shown by \citeA{lewin76}, \citeA{carson86}, \citeA{bartoldy02}, and \citeA{rinaldi03}.
%...has been shown \cite{jskilbye}.
%...has been shown \cite{lewin76,carson86,bartoldy02,rinaldi03}.
%... \cite <i.e.>[]{lewin76,carson86,bartoldy02,rinaldi03}.
%...has been shown by \cite <e.g.,>[and others]{lewin76}.
%
% apacite uses < > for prenotes and [ ] for postnotes
% DO NOT use other cite commands (e.g., \citet, \citep, \citeyear, \nocite, \citealp, etc.).
%



\end{document}



More Information and Advice:

%% ------------------------------------------------------------------------ %%
%
%  SECTION HEADS
%
%% ------------------------------------------------------------------------ %%

% Capitalize the first letter of each word (except for
% prepositions, conjunctions, and articles that are
% three or fewer letters).

% AGU follows standard outline style; therefore, there cannot be a section 1 without
% a section 2, or a section 2.3.1 without a section 2.3.2.
% Please make sure your section numbers are balanced.
% ---------------
% Level 1 head
%
% Use the \section{} command to identify level 1 heads;
% type the appropriate head wording between the curly
% brackets, as shown below.
%
%An example:
%\section{Level 1 Head: Introduction}
%
% ---------------
% Level 2 head
%
% Use the \subsection{} command to identify level 2 heads.
%An example:
%\subsection{Level 2 Head}
%
% ---------------
% Level 3 head
%
% Use the \subsubsection{} command to identify level 3 heads
%An example:
%\subsubsection{Level 3 Head}
%
%---------------
% Level 4 head
%
% Use the \subsubsubsection{} command to identify level 3 heads
% An example:
%\subsubsubsection{Level 4 Head} An example.
%
%% ------------------------------------------------------------------------ %%
%
%  IN-TEXT LISTS
%
%% ------------------------------------------------------------------------ %%
%
% Do not use bulleted lists; enumerated lists are okay.
% \begin{enumerate}
% \item
% \item
% \item
% \end{enumerate}
%
%% ------------------------------------------------------------------------ %%
%
%  EQUATIONS
%
%% ------------------------------------------------------------------------ %%

% Single-line equations are centered.
% Equation arrays will appear left-aligned.

Math coded inside display math mode \[ ...\]
 will not be numbered, e.g.,:
 \[ x^2=y^2 + z^2\]

 Math coded inside \begin{equation} and \end{equation} will
 be automatically numbered, e.g.,:
 \begin{equation}
 x^2=y^2 + z^2
 \end{equation}


% To create multiline equations, use the
% \begin{eqnarray} and \end{eqnarray} environment
% as demonstrated below.
\begin{eqnarray}
  x_{1} & = & (x - x_{0}) \cos \Theta \nonumber \\
        && + (y - y_{0}) \sin \Theta  \nonumber \\
  y_{1} & = & -(x - x_{0}) \sin \Theta \nonumber \\
        && + (y - y_{0}) \cos \Theta.
\end{eqnarray}

%If you don't want an equation number, use the star form:
%\begin{eqnarray*}...\end{eqnarray*}

% Break each line at a sign of operation
% (+, -, etc.) if possible, with the sign of operation
% on the new line.

% Indent second and subsequent lines to align with
% the first character following the equal sign on the
% first line.

% Use an \hspace{} command to insert horizontal space
% into your equation if necessary. Place an appropriate
% unit of measure between the curly braces, e.g.
% \hspace{1in}; you may have to experiment to achieve
% the correct amount of space.


%% ------------------------------------------------------------------------ %%
%
%  EQUATION NUMBERING: COUNTER
%
%% ------------------------------------------------------------------------ %%

% You may change equation numbering by resetting
% the equation counter or by explicitly numbering
% an equation.

% To explicitly number an equation, type \eqnum{}
% (with the desired number between the brackets)
% after the \begin{equation} or \begin{eqnarray}
% command.  The \eqnum{} command will affect only
% the equation it appears with; LaTeX will number
% any equations appearing later in the manuscript
% according to the equation counter.
%

% If you have a multiline equation that needs only
% one equation number, use a \nonumber command in
% front of the double backslashes (\\) as shown in
% the multiline equation above.

% If you are using line numbers, remember to surround
% equations with \begin{linenomath*}...\end{linenomath*}

%  To add line numbers to lines in equations:
%  \begin{linenomath*}
%  \begin{equation}
%  \end{equation}
%  \end{linenomath*}



